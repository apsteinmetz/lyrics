---
title: "What Do the Ramones Want?"
output: html_notebook
---
Recently I saw a tweet that shared this hilarious poster.
![](https://images.squarespace-cdn.com/content/v1/51f30200e4b086a9c879cd57/1376157201580-0W1TZ1X85OQAHMLRS6OI/ke17ZwdGBToddI8pDm48kPoswlzjSVMM-SxOp7CV59BZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIeQMKeWYgwh6Mn73n2eZmZLHHpcPIxgL2SArp_rN2M_AKMshLAGzx4R3EDFOm1kBS/Wants4thEdition.jpg?format=1000w)

Dan Gneiding (aka Grayhood) is the graphic designer who created this.  You can buy it [here](http://grayhood.com/shop/ramones-vs-misfits-1-2-3-4th-edition)

Very cool, but is it accurate?  You may accuse me of being that pedantic "Comic Book Guy" from "The Simpsons" but, when I saw it, I immediately wondered how I could tally these Ramones lyrics myself.

<iframe src="https://giphy.com/embed/26tk0Emxz61hdKEog" width="480" height="360" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/season-13-the-simpsons-13x8-26tk0Emxz61hdKEog">via GIPHY</a></p>

```{r}
#```{r global_options, include=FALSE}
#knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.path='Figs/',
#                      echo=FALSE, warning=FALSE, message=FALSE)
```

```{r message=FALSE, warning=FALSE}
#devtools::install_github("dmi3kno/polite")
library(tidyverse)
library(tidytext)
library(rvest)
library(polite)
library(reshape2)
library(wordcloud)
library(scales)

# very dark theme for ggplot
source("ggplot_theme_black.r")

```

Get names of all Ramones songs from azlyrics.com.  Use the `polite` package so we obey the robots.txt instructions at the site.
```{r}
if (file.exists("data/ramones_song_list.rdata")){
  load("data/ramones_song_list.rdata")
} else {
# be polite. get scraping parameters.
base_url <- "https://azlyrics.com"
 song_list_raw <- polite::bow("https://azlyrics.com/r/ramones.html") %>% 
   polite::scrape() %>%
   rvest::html_nodes("#listAlbum a")

song_list <- song_list_raw %>% 
  rvest::html_attr("href") %>% 
  tibble::enframe(name = NULL,value = "lyric_url") %>% 
  dplyr::mutate(song_name = html_text(song_list_raw)) %>% 
  mutate(lyric_url=str_replace(lyric_url,"..",base_url))
save(song_list,file="data/ramones_song_list.rdata")
}

song_list
```

Now get all the lyrics.
```{r}
#make a function to get lyrics

get_lyric <- function(lyric_url){
  lyric <- bow(lyric_url) %>% 
    scrape() %>% 
    #    /html/body/div[4]/div/div[2]/div[5]
    # body > div.container.main-page > div > div.col-xs-12.col-lg-8.text-center > div:nth-child(8)
    html_nodes("div") %>%
    #not happy with this.  relies on the lyrics always being the 22nd `<div>` tag on the page.
    .[22] %>% 
    html_text() %>%
    str_remove_all("\r") %>% 
    str_replace_all("\n"," ") %>% 
    str_trim()
  return(lyric)
}

if (file.exists("data/raw_ramones_lyrics.rdata")){
  load("data/raw_ramones_lyrics.rdata")
} else {
  all_lyrics <- NULL
  all_urls <- song_list$lyric_url
  for (lyric_url in all_urls){
    lyric <- get_lyric(lyric_url)
    all_lyrics <- c(all_lyrics,lyric)
    
  }
  save(all_lyrics,file="data/raw_ramones_lyrics.rdata")
}

print(all_lyrics[1])
```

Make into a complete data frame with all the trimmings
```{r}
ramones_lyrics <- song_list %>%  
  bind_cols(enframe(all_lyrics,name="corpus_order",value="lyrics")) %>% 
  mutate(band="Ramones") %>% 
  select(band,song_name,lyrics,lyric_url)

ramones_lyrics
```

```{r}
lyric_words <- ramones_lyrics %>% select(-band,-lyric_url) %>% unnest_tokens(word,lyrics)

```

```{r}
lyric_words_cleaned <- lyric_words %>% anti_join(get_stopwords(),by="word")

#quick sentiment analysis
positive <- get_sentiments("bing") %>%
  filter(sentiment == "positive")

negative <- get_sentiments("bing") %>%
  filter(sentiment == "negative")

lyric_words_cleaned %>%
  semi_join(positive,by="word") %>%
  group_by(song_name) %>% 
  count(word) %>% 
  group_by(song_name) %>% 
  tally(sort = TRUE,name="Happy Words")
  
```

```{r}
lyric_words_cleaned %>%
  semi_join(negative,by="word") %>%
  group_by(song_name) %>% 
  count(word) %>% 
  group_by(song_name) %>% 
  tally(sort = TRUE,name="Sad Words")
  

```

```{r}
lyric_words_cleaned %>%
  inner_join(get_sentiments("bing"),by="word") %>%
  group_by(song_name) %>% 
  count(sentiment,sort=TRUE) %>% 
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  group_by(song_name) %>% 
  summarise(net_sentiment=sum(n)) %>% 
  filter(abs(net_sentiment) > 10) %>%
  mutate(song_name = reorder(song_name, net_sentiment)) %>%
  mutate(sentiment=ifelse(net_sentiment<0,"Negative","Positive")) %>% 
  ggplot(aes(song_name, net_sentiment, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(title="How Happy are Ramones Songs?",
       y = "Balance of Postive to Negative Words",
       x= "") +
    theme_black() +
  scale_fill_manual(values = c("red","darkgrey"))+
  theme(axis.text.y =  element_text(size=7,hjust=1)) 
```

What is overall sentiment?
Filter out "punk" since this word is not a negative Ramones songs.
```{r}
lyric_words_cleaned %>%
  filter(word != "punk") %>% 
  inner_join(get_sentiments("bing"),by="word") %>%
  count(sentiment,sort=TRUE) %>% 
  ggplot(aes(sentiment, n, fill = sentiment)) +
  geom_col() +
  labs(title="How Happy are the Ramones?",
       y = "Word Count (excluding 'Punk')",
       x= "") +
    theme_black() +
  scale_fill_manual(values = c("red","darkgrey"))+
  theme(axis.text.y =  element_text(size=7,hjust=1)) 

```
```{r}
{par(bg="black")
lyric_words_cleaned %>%
  inner_join(get_sentiments("bing"),by="word") %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
#  comparison.cloud(colors = c("#F8766D", "#00BFC4"),
#                   max.words = 100)
  comparison.cloud(colors = c("red", "grey60"),
                   max.words = 100,
                   title.bg.colors="grey60")
}
```

Now lets find what the Ramones Want.  Let's look at the most common n-grams, which would include the phrases like "I want" and "I wanna."

Start with shortest n-gram that is a complete thought and work up to longer phrases.  We take the the shortest phrase that makes sense unless appending more words doesn't change the frequency.  Then we take the longer phrase.  For instance if "I wanna steal some money" and "I wanna steal from the rich" both exist we take "I wanna steal" since it would have a higher frequency than either longer phrase.  In this case, the only phrase starting with "I wanna steal"  is "I wanna steal from the rich" so we use that.
```{r}
want_phrases <- "^(i wanna |i want |we want |we wanna |i wanted |i just want |i just wanna )"

get_ngrams <- function(lyric_df,n){
  min_instance = 0
  lyric_ngram <- ramones_lyrics %>% 
    select(-band,-lyric_url) %>% 
    unnest_tokens(ngram,lyrics,token = "ngrams",n=n) %>% 
    group_by(ngram) %>% 
    filter(str_detect(ngram,want_phrases)) %>% 
    count() %>% 
    arrange(desc(n)) %>% 
    filter(n>min_instance) %>% mutate(want=str_remove(ngram,want_phrases)) %>% 
    rownames_to_column()
  return(lyric_ngram)
  
}

want <- ramones_lyrics %>% get_ngrams(3)
want
```

What a human needs to do is decide which phrases are complete thoughts.  We manually select the row numbers to build our ultimate table and build a longer n-gram table to flesh out those that are not.

```{r}
ultimate_want <- tibble()
ultimate_want <- bind_rows(ultimate_want,want[c(2,4,8,11,16,20,21),])
want <- ramones_lyrics %>% get_ngrams(4)
want
```

This is a manual,iterative process of taking ever-longer n-grams until we don't see any sensible new phrases.  I won't bore you with every iteration so let's skip ahead

```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(2,4,6,22,24,25,34,42,45,54,58),])
want <- ramones_lyrics %>% get_ngrams(5)
want

```

```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(7,15,22,31,32,43),])
want <- ramones_lyrics %>% get_ngrams(6)
want

```
```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(9,14,17,27,28,29,41),])
want <- ramones_lyrics %>% get_ngrams(7)
want
```

```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(1,5,12,22,87),])
ultimate_want <- ultimate_want %>% arrange(desc(n)) %>% select(-rowname)
ultimate_want
```
Now strip some extraneous words so all the phrases sound reasonable.
```{r}
ultimate_want <- ultimate_want %>% 
  mutate(want = str_remove(want,"^to |ed |wanna |^was to |^is |^be with ")) %>% 
  group_by(want) %>%
  summarise(n=sum(n))
ultimate_want
```

```{r}
ultimate_want %>% mutate(want=reorder(want,n)) %>% 
  ggplot(aes(want,n)) + geom_col()+coord_flip() +
  theme_black() +
  theme(axis.text.y = element_text(hjust=1,size=10))+ 
  scale_fill_manual(values = c("red","darkgrey"))

```
What DON'T the Ramones want? Once again, we go through the same iterative process with different phrase stems.
```{r}
want_phrases <- "^(i don't wanna |i don't want |we don't want |we don't wanna |i didn't want )"

want <- ramones_lyrics %>% get_ngrams(5) %>% mutate(n = -n)
want
```


```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(1),])
want <- ramones_lyrics %>% get_ngrams(6) %>% mutate(n = -n)
want
```


```{r  include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(1,2,3),])
want <- ramones_lyrics %>% get_ngrams(7) %>% mutate(n = -n)
want

```

```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(3,5),])
want <- ramones_lyrics %>% get_ngrams(8) %>% mutate(n = -n)
want

```
```{r include=FALSE}
ultimate_want <- bind_rows(ultimate_want,want[c(5,9),])
want <- ramones_lyrics %>% get_ngrams(9) %>% mutate(n = -n)
want

```
```{r include=FALSE}
# nuthin this round ultimate_want <- bind_rows(ultimate_want,want[c(5,9),])
want <- ramones_lyrics %>% get_ngrams(10) %>% mutate(n = -n)
want

```

```{r}
#there it is - Pet Sematary!
ultimate_want <- bind_rows(ultimate_want,want[c(6),])
ultimate_want <- ultimate_want %>% mutate(want = str_remove(want,"to ")) %>% 
  group_by(want) %>%
  summarise(n=sum(n)) %>%   
  mutate(sentiment = ifelse(n > 0,"want","don't want")) %>% 
  arrange(desc(n)) %>% 
  mutate(want=str_to_title(want))
ultimate_want
```

```{r}
ultimate_want %>% mutate(want=reorder(want,n)) %>% 
  ggplot(aes(want,n,fill=sentiment)) + geom_col()+coord_flip()+
  labs(title="What Do The Ramones Want?",
       y="How Much Do The Ramones Want It?",
       x="") +
  theme_black() +
  scale_fill_manual(values = c("red","darkgrey"))+
  theme(axis.text.y =  element_text(size=7,hjust=1)) 
```

Sometimes, late at night, after everyone else is asleep, I hide under the covers, open my laptop and look at... pie charts.  Ed Tufte says I will go blind if I keep doing it.  Still, for the sake of bringing this full circle let's make a version of Grayhood's poster with our data.  So it's not a complete mess we lump any phrases that occur less than 4 times in "Other."  That takes some of the fun out of things since we lose memorable phrases like "I wanna sniff some glue" the poster includes.  This is data science, not art.  It's not supposed to be fun! While I use ggplot2 pretty much exclusively, the base R `pie` plot produces pretty clean results that approximate the style of the poster with no embellishment. 

```{r}
collapsed_want <- ultimate_want %>%
  filter(sentiment=="want") %>%
  mutate(want = ifelse(n<3,"Other",want)) %>%
  group_by(want) %>% 
  summarise(n=sum(n)) %>% 
  arrange(desc(n)) %>% 
  {.}

 with(collapsed_want,
      pie(n, 
          labels=paste0(as.character(want), " ", n, "%"),
          col=c("brown","red","black","darkblue","pink","purple"),
          radius=1,
          density=30,
          bg="sienna",
          main="The Ramones Wanna..."))
```

